; generated by vstart.sh on Mon Mar 30 23:50:42 CDT 2020
[client.vstart.sh]
        num mon = 1
        num osd = 1
        num mds = 0
        num mgr = 1
        num rgw = 0

[global]
        debug bluestore = 0
	debug mon = 0
        debug monc = 0
        debug mds = 0
        debug ms = 0
        debug osd = 0
        debug mgrc = 0
        debug bdev = 0
        debug bluefs = 0
        debug rocksdb = 0
	debug objecter = 0

        fsid = 5c72495d-228d-48a1-9ce5-5ae648851f0a
        osd failsafe full ratio = .99
        mon osd full ratio = .99
        mon osd nearfull ratio = .99
        mon osd backfillfull ratio = .99
        erasure code dir = /users/yzhan298/ceph/build/lib
        plugin dir = /users/yzhan298/ceph/build/lib
        filestore fd cache size = 32
        run dir = /users/yzhan298/ceph/build/out
        crash dir = /users/yzhan298/ceph/build/out
        enable experimental unrecoverable data corrupting features = *
        osd_crush_chooseleaf_type = 0
        debug asok assert abort = true

        ms bind msgr2 = true
        ms bind msgr1 = true

	bluestore block = /dev/sdc
	bluestore block path = /dev/sdc
	bluestore fsck on mkfs = false
	bluestore fsck on mount = false
	bluestore fsck on umount = false
	bluestore block db path = 
	bluestore block wal path = 
	bluestore block wal create = false
	bluestore block db create = false

        lockdep = true
        auth cluster required = cephx
        auth service required = cephx
        auth client required = cephx
[client]
        keyring = /users/yzhan298/ceph/build/keyring
        log file = /users/yzhan298/ceph/build/out/$name.$pid.log
        admin socket = /tmp/ceph-asok.ll4oXA/$name.$pid.asok

        ; needed for s3tests
        rgw crypt s3 kms backend = testing
        rgw crypt s3 kms encryption keys = testkey-1=YmluCmJvb3N0CmJvb3N0LWJ1aWxkCmNlcGguY29uZgo= testkey-2=aWIKTWFrZWZpbGUKbWFuCm91dApzcmMKVGVzdGluZwo=
        rgw crypt require ssl = false
        ; uncomment the following to set LC days as the value in seconds;
        ; needed for passing lc time based s3-tests (can be verbose)
        ; rgw lc debug interval = 10
        ; The following settings are for SSE-KMS with Vault
        ; rgw crypt s3 kms backend = vault
        ; rgw crypt vault auth = token
        ; rgw crypt vault addr = http://127.0.0.1:8200
        ; rgw crypt vault token file = /path/to/token.file

	bluestore block = /dev/sdc
	bluestore block path = /dev/sdc
	bluestore fsck on mkfs = false
	bluestore fsck on mount = false
	bluestore fsck on umount = false
	bluestore block db path = 
	bluestore block wal path = 
	bluestore block wal create = false
	bluestore block db create = false

[mds]

        log file = /users/yzhan298/ceph/build/out/$name.log
        admin socket = /tmp/ceph-asok.ll4oXA/$name.asok
        chdir = ""
        pid file = /users/yzhan298/ceph/build/out/$name.pid
        heartbeat file = /users/yzhan298/ceph/build/out/$name.heartbeat

        mds data = /users/yzhan298/ceph/build/dev/mds.$id
        mds root ino uid = 0
        mds root ino gid = 0
	bluestore block = /dev/sdc
	bluestore block path = /dev/sdc
	bluestore fsck on mkfs = false
	bluestore fsck on mount = false
	bluestore fsck on umount = false
	bluestore block db path = 
	bluestore block wal path = 
	bluestore block wal create = false
	bluestore block db create = false

[mgr]
        mgr data = /users/yzhan298/ceph/build/dev/mgr.$id
        mgr module path = /users/yzhan298/ceph/src/pybind/mgr
        ceph daemon path = /users/yzhan298/ceph/src/ceph-daemon

        log file = /users/yzhan298/ceph/build/out/$name.log
        admin socket = /tmp/ceph-asok.ll4oXA/$name.asok
        chdir = ""
        pid file = /users/yzhan298/ceph/build/out/$name.pid
        heartbeat file = /users/yzhan298/ceph/build/out/$name.heartbeat

	bluestore block = /dev/sdc
	bluestore block path = /dev/sdc
	bluestore fsck on mkfs = false
	bluestore fsck on mount = false
	bluestore fsck on umount = false
	bluestore block db path = 
	bluestore block wal path = 
	bluestore block wal create = false
	bluestore block db create = false

[osd]

        log file = /users/yzhan298/ceph/build/out/$name.log
        admin socket = /tmp/ceph-asok.ll4oXA/$name.asok
        chdir = ""
        pid file = /users/yzhan298/ceph/build/out/$name.pid
        heartbeat file = /users/yzhan298/ceph/build/out/$name.heartbeat

        osd_check_max_object_name_len_on_startup = false
        osd data = /users/yzhan298/ceph/build/dev/osd$id
        osd journal = /users/yzhan298/ceph/build/dev/osd$id/journal
        osd journal size = 100
        osd class tmp = out
        osd class dir = /users/yzhan298/ceph/build/lib
        osd class load list = *
        osd class default list = *
        filestore wbthrottle xfs ios start flusher = 10
        filestore wbthrottle xfs ios hard limit = 20
        filestore wbthrottle xfs inodes hard limit = 30
        filestore wbthrottle btrfs ios start flusher = 10
        filestore wbthrottle btrfs ios hard limit = 20
        filestore wbthrottle btrfs inodes hard limit = 30
        bluestore fsck on mount = true
        bluestore block create = true
        bluestore block db path = /users/yzhan298/ceph/build/dev/osd$id/block.db.file
        bluestore block db size = 1073741824
        bluestore block db create = true
        bluestore block wal path = /users/yzhan298/ceph/build/dev/osd$id/block.wal.file
        bluestore block wal size = 1048576000
        bluestore block wal create = true

	;bluestore rocksdb options = compression=kNoCompression,max_write_buffer_number=8,min_write_buffer_number_to_merge=4,recycle_log_file_num=4,write_buffer_size=1073741824,writable_file_max_buffer_size=0,compaction_readahead_size=8388608,max_background_compactions=2
	
	osd_op_num_shards = 1
	osd_op_num_threads_per_shard = 2
	enable_throttle = false
        enable_codel = false
	enable_batch_bound = false
	kv_queue_upper_bound_size = 30
	bluestore_throttle_bytes = 100000000
	bluestore_throttle_deferred_bytes = 100000000
	bluestore_throttle_cost_per_io = 0
	bluestore_throttle_cost_per_io_hdd = 100000
	bluestore_throttle_cost_per_io_ssd = 100000
	bdev_block_size = 4096
	bluestore_min_alloc_size = 0
	bluestore_min_alloc_size_hdd = 65536
	bluestore_min_alloc_size_ssd =  16384
	bluestore_max_alloc_size = 0
	bluestore_prefer_deferred_size = 0
	bluestore_prefer_deferred_size_hdd = 0
        bluestore_prefer_deferred_size_ssd = 0

        ; kstore
        kstore fsck on mount = true
        osd objectstore = bluestore

	bluestore block = /dev/sdc
	bluestore block path = /dev/sdc
	bluestore fsck on mkfs = false
	bluestore fsck on mount = false
	bluestore fsck on umount = false
	bluestore block db path = 
	bluestore block wal path = 
	bluestore block wal create = false
	bluestore block db create = false

[mon]
        mgr initial modules = restful iostat

        log file = /users/yzhan298/ceph/build/out/$name.log
        admin socket = /tmp/ceph-asok.ll4oXA/$name.asok
        chdir = ""
        pid file = /users/yzhan298/ceph/build/out/$name.pid
        heartbeat file = /users/yzhan298/ceph/build/out/$name.heartbeat


        debug mon = 10
        debug ms = 1
	bluestore block = /dev/sdc
	bluestore block path = /dev/sdc
	bluestore fsck on mkfs = false
	bluestore fsck on mount = false
	bluestore fsck on umount = false
	bluestore block db path = 
	bluestore block wal path = 
	bluestore block wal create = false
	bluestore block db create = false

        mon cluster log file = /users/yzhan298/ceph/build/out/cluster.mon.$id.log
        osd pool default erasure code profile = plugin=jerasure technique=reed_sol_van k=2 m=1 crush-failure-domain=osd
[mon.a]
        host = c220g2-011110
        mon data = /users/yzhan298/ceph/build/dev/mon.a
[global]
        mon host =  [v2:128.105.145.113:40850,v1:128.105.145.113:40851]
[mgr.x]
        host = c220g2-011110
[osd.0]
        host = c220g2-011110
